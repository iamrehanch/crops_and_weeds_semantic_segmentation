import torch
import torch.nn as nn
import torch.nn.functional as F
from torchsummary import summary
from ptflops import get_model_complexity_info
from thop import profile

    
class DBConv(nn.Sequential): #class
    '''
    double 3x3 conv layers with Batch normalization and ReLU
    '''
    def __init__(self, in_channels, out_channels):
        conv_layers = [
            nn.Conv2d(in_channels, out_channels, 3),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(),
            nn.Conv2d(out_channels, out_channels, 3),
            nn.BatchNorm2d(out_channels),
            nn.ReLU()
        ]
        super(DBConv, self).__init__(*conv_layers)


class ContractingPath(nn.Module):
    def __init__(self, in_channels, first_outchannels):
        super(ContractingPath, self).__init__()
        self.conv1 = DBConv(in_channels, first_outchannels)
        self.conv2 = DBConv(first_outchannels, first_outchannels*2)
        self.conv3 = DBConv(first_outchannels*2, first_outchannels*4)
        self.conv4 = DBConv(first_outchannels*4, first_outchannels*8)

        self.maxpool = nn.MaxPool2d(2)
    
    def forward(self, x):
        output1 = self.conv1(x) 
        output = self.maxpool(output1) 
        output2 = self.conv2(output) 
        output = self.maxpool(output2) 
        output3 = self.conv3(output) 
        output = self.maxpool(output3) 
        output4 = self.conv4(output) 
        output = self.maxpool(output4) 
        return output1, output2, output3, output4, output


class ExpansivePath(nn.Module):
    '''
    pass1, pass2, pass3, pass4 are the featuremaps passed from Contracting path
    '''
    def __init__(self, in_channels):
        super(ExpansivePath, self).__init__()
        # input (size)
        self.upconv1 = nn.ConvTranspose2d(in_channels, in_channels//2, 2, 2) 
        self.conv1 = DBConv(in_channels, in_channels//2) 
        
        self.upconv2 = nn.ConvTranspose2d(in_channels//2, in_channels//4, 2, 2) 
        self.conv2 = DBConv(in_channels//2, in_channels//4) 
        
        self.upconv3 = nn.ConvTranspose2d(in_channels//4, in_channels//8, 2, 2) 
        self.conv3 = DBConv(in_channels//4, in_channels//8) 

        self.upconv4 = nn.ConvTranspose2d(in_channels//8, in_channels//16, 2, 2) 
        self.conv4 = DBConv(in_channels//8, in_channels//16) 
        
        # for match output shape with 

    def forward(self, x, pass1, pass2, pass3, pass4):
        # input (size)
        output = self.upconv1(x)
        diffY = pass4.size()[2] - output.size()[2]
        diffX = pass4.size()[3] - output.size()[3]
        output = F.pad(output, (diffX//2, diffX-diffX//2, diffY//2, diffY-diffY//2))
        output = torch.cat((output, pass4), 1) 
        output = self.conv1(output) 
        
        output = self.upconv2(output) 
        diffY = pass3.size()[2] - output.size()[2]
        diffX = pass3.size()[3] - output.size()[3]
        output = F.pad(output, (diffX//2, diffX-diffX//2, diffY//2, diffY-diffY//2))
        output = torch.cat((output, pass3), 1) 
        output = self.conv2(output) 
        
        output = self.upconv3(output) 
        diffY = pass2.size()[2] - output.size()[2]
        diffX = pass2.size()[3] - output.size()[3]
        output = F.pad(output, (diffX//2, diffX-diffX//2, diffY//2, diffY-diffY//2))
        output = torch.cat((output, pass2), 1) 
        output = self.conv3(output) 
        
        output = self.upconv4(output) 
        diffY = pass1.size()[2] - output.size()[2]
        diffX = pass1.size()[3] - output.size()[3]
        output = F.pad(output, (diffX//2, diffX-diffX//2, diffY//2, diffY-diffY//2)) 
        output = torch.cat((output, pass1), 1) 
        output = self.conv4(output) 
        
        return output

class Unet(nn.Module):
    def __init__(self, in_channels=3, first_outchannels=64, num_classes=3, init_weights=True):
        super(Unet, self).__init__()
        self.contracting_path = ContractingPath(in_channels=in_channels, first_outchannels=first_outchannels)
        self.middle_conv = DBConv(first_outchannels*8, first_outchannels*16)
        self.expansive_path = ExpansivePath(in_channels=first_outchannels*16)
        self.conv_1x1 = nn.Conv2d(first_outchannels, num_classes, 1)
        
        if init_weights:
            print('initialize weights...')
            self._initialize_weights()
    
    def forward(self, x):
        factor=4
        orgh, orgw = x.shape[-2], x.shape[-1]
        H, W = ((orgh+factor)//factor)*factor, ((orgw+factor)//factor)*factor
        padh = H-orgh if orgh%factor!=0 else 0
        padw = W-orgw if orgh%factor!=0 else 0
        x = F.pad(x, (4, padw+4, 4, padh+4), mode='reflect')
        # image = F.pad(x, (4, 4, 4, 4))
        pass1, pass2, pass3, pass4, output = self.contracting_path(x)
        output = self.middle_conv(output)
        output = self.expansive_path(output, pass1, pass2, pass3, pass4)
        output = self.conv_1x1(output)
        output = output[:, :, :orgh, :orgw]
        return output

    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu') # He initialization
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
